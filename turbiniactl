#!/usr/bin/env python
#
# Copyright 2015 Google Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
"""Command line interface for Turbinia."""
# pylint: disable=bad-indentation

import argparse
import logging
import sys

try:
  import psq
except ImportError:
  print 'PSQ Module cannot be loaded, please see:'
  print 'https://github.com/GoogleCloudPlatform/psq'
  sys.exit(1)

from turbinia import config
from turbinia.config import logger
from turbinia import evidence
from turbinia import task_manager
from turbinia import VERSION
from turbinia.pubsub import TurbiniaRequest

log = logging.getLogger('turbinia')
logger.setup()

if __name__ == '__main__':
  # TODO(aarontp): Add 'startserver' command
  # TODO(aarontp): Allow for single run mode when specifying evidence
  #                which will also terminate the task manager after evidence has
  #                been processed.
  parser = argparse.ArgumentParser()
  parser.add_argument('-v', '--verbose', action='store_true', help='verbose')
  # TODO(aarontp): Turn off debug by default later
  parser.add_argument(
      '-d', '--debug', action='store_true', help='debug', default=True)
  parser.add_argument('-o', '--output_dir', help='Directory path for output')
  parser.add_argument('-L', '--log_file', help='Log file')
  parser.add_argument(
      '-S',
      '--server',
      action='store_true',
      help='Run Turbinia Server indefinitely')
  parser.add_argument(
      '-V',
      '--version',
      action='version',
      version=VERSION,
      help='Show the version')

  subparsers = parser.add_subparsers(
      dest='command', title='Commands', metavar='<command>')

  # TODO(aarontp): Find better way to specify these that allows for multiple
  # pieces of evidence to be submitted. Maybe automagically create different
  # commands based on introspection of evidence objects?
  # RawDisk
  parser_rawdisk = subparsers.add_parser(
      'rawdisk', help='Process RawDisk as Evidence')
  parser_rawdisk.add_argument(
      '-l', '--local_path', help='Local path to the evidence', required=True)
  parser_rawdisk.add_argument(
      '-s',
      '--source',
      help='Description of the source of the evidence',
      required=False)
  parser_rawdisk.add_argument(
      '-n', '--name', help='Descriptive name of the evidence', required=False)

  # Google Cloud Disk
  parser_googleclouddisk = subparsers.add_parser(
      'googleclouddisk',
      help='Process Google Cloud Persistent Disk as Evidence')
  parser_googleclouddisk.add_argument(
      '-d', '--disk_name', help='Google Cloud name for disk', required=True)
  parser_googleclouddisk.add_argument(
      '-p', '--project', help='Project that the disk is associated with',
      required=True)
  parser_googleclouddisk.add_argument(
      '-z', '--zone', help='Geographic zone the disk exists in',
      required=True)
  parser_googleclouddisk.add_argument(
      '-s',
      '--source',
      help='Description of the source of the evidence',
      required=False)
  parser_googleclouddisk.add_argument(
      '-n', '--name', help='Descriptive name of the evidence', required=False)

  # Directory
  parser_directory = subparsers.add_parser(
      'directory', help='Process a directory as Evidence')
  parser_directory.add_argument(
      '-l', '--local_path', help='Local path to the evidence', required=True)
  parser_directory.add_argument(
      '-s',
      '--source',
      help='Description of the source of the evidence',
      required=False)
  parser_directory.add_argument(
      '-n', '--name', help='Descriptive name of the evidence', required=False)

  # List Jobs
  parser_listjobs = subparsers.add_parser(
      'listjobs', help='List all available jobs')

  # PSQ Worker
  parser_psqworker = subparsers.add_parser('psqworker', help='Run PSQ worker')
  parser_psqworker.add_argument(
      '-S',
      '--single_threaded',
      action='store_true',
      help='Run PSQ Worker in a single thread',
      required=False)

  # Server
  parser_server = subparsers.add_parser('server', help='Run Turbinia Server')

  args = parser.parse_args()
  if args.verbose:
    log.setLevel(logging.INFO)
  elif args.debug:
    log.setLevel(logging.DEBUG)
  else:
    log.setLevel(logging.WARNING)

  # TaskManager
  # TODO(aarontp): Move some of this to turbinia/__init__.py
  config.LoadConfig()
  task_manager_ = task_manager.get_task_manager()
  task_manager_.setup()

  if args.output_dir:
    config.OUTPUT_DIR = args.output_dir
  if args.log_file:
    config.LOG_FILE = args.log_file

  evidence_ = None
  if args.command == 'rawdisk':
    args.name = args.name if args.name else args.local_path
    evidence_ = evidence.RawDisk(
        name=args.name, local_path=args.local_path, source=args.source)
  elif args.command == 'directory':
    args.name = args.name if args.name else args.local_path
    evidence_ = evidence.Directory(
        name=args.name, local_path=args.local_path, source=args.source)
  elif args.command == 'googleclouddisk':
    args.name = args.name if args.name else args.disk_name
    evidence_ = evidence.GoogleCloudDisk(
        name=args.name, disk_name=args.disk_name, project=args.project,
        zone=args.zone, source=args.source)
  elif args.command == 'psqworker':
    # Set up root logger level which is normally set by the psqworker command
    # which we are bypassing.
    logger.setup(root=True)
    if args.single_threaded:
      worker = psq.Worker(queue=task_manager_.psq)
    else:
      worker = psq.MultiprocessWorker(queue=task_manager_.psq)
    log.info(
        u'Starting PSQ listener on queue {0:s}'.format(task_manager_.psq.name))
    worker.listen()
  elif args.command == 'server':
    log.info(u'Running Turbinia Server.')
    task_manager_.run()
  elif args.command == 'listjobs':
    log.info(u'Available Jobs:')
    log.info(
        '\n'.join(['\t{0:s}'.format(job.name) for job in task_manager_.jobs]))
  else:
    log.warning(u'Command {0:s} not implemented.'.format(args.command))

  # If we have evidence to process and we also want to run as a server, then
  # we'll just process the evidence directly rather than send it through the
  # PubSub frontend interface.  If we're not running as a server then we will
  # create a new TurbiniaRequest and send it over PubSub.
  if evidence_ and args.server:
    task_manager_.add_evidence(evidence_)
    task_manager_.run()
  elif evidence_:
    request = TurbiniaRequest()
    request.evidence.append(evidence_)
    log.info(
        u'Creating PubSub request with evidence {0:s}'.format(evidence_.name))
    task_manager_.server_pubsub.send_request(request)

  log.info(u'Done.')
  sys.exit(0)
